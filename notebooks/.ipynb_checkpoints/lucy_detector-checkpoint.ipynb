{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import shutil\n",
    "\n",
    "from PIL import Image \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH, IMG_HEIGHT = 224, 224\n",
    "BATCH_SIZE = 64\n",
    "TRAIN_SAMPLES = 122\n",
    "NUM_CLASSES = 1\n",
    "\n",
    "# TRAIN_DATA_DIR = \"/Users/johngalvin/Desktop/GitHub/Lucy_Detector/data/split_dataset/train/lucy\"\n",
    "# VAL_DATA_DIR = \"/Users/johngalvin/Desktop/GitHub/Lucy_Detector/data/split_dataset/val/lucy\"\n",
    "# TEST_DATA_DIR = \"/Users/johngalvin/Desktop/GitHub/Lucy_Detector/data/split_dataset/test/lucy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data into Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert .JPG and .jpg files to .jpeg\n",
    "\n",
    "path = \"/Users/johngalvin/Desktop/GitHub/Lucy_Detector/data/images\"\n",
    "for file in os.listdir(path):\n",
    "    if file.endswith(\".JPG\") or file.endswith(\".jpg\"):\n",
    "        img = Image.open(path + \"/\" + file)\n",
    "        file_name, file_ext = os.path.splitext(file)\n",
    "        new_name = file_name + \".jpeg\"\n",
    "        img.save(path + \"/\" + new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list of the image files\n",
    "image_files = glob(\"/Users/johngalvin/Desktop/GitHub/Lucy_Detector/data/images/*.jpeg\")\n",
    "\n",
    "# Strip the extensions\n",
    "image_names = [name.replace(\".jpeg\",\"\") for name in image_files]\n",
    "\n",
    "# Split into train and test\n",
    "train_names, test_names = train_test_split(image_names, test_size=0.2)\n",
    "\n",
    "def batch_move_files(file_list, source_path, destination_path):\n",
    "    \"\"\"Moves the jpeg and xml file pairs to destination path from source path\"\"\"\n",
    "    \n",
    "    for file in file_list:\n",
    "        image = file + \".jpeg\"\n",
    "        xml = file + \".xml\"\n",
    "        shutil.move(os.path.join(source_path, image), destination_path)\n",
    "        shutil.move(os.path.join(source_path, xml), destination_path)\n",
    "    return\n",
    "\n",
    "source_dir = \"/Users/johngalvin/Desktop/GitHub/Lucy_Detector/data/images/\"\n",
    "test_dir = \"/Users/johngalvin/Desktop/GitHub/Lucy_Detector/data/test/\"\n",
    "train_dir = \"/Users/johngalvin/Desktop/GitHub/Lucy_Detector/data/train/\"\n",
    "batch_move_files(test_names, source_dir, test_dir)\n",
    "batch_move_files(train_names, source_dir, train_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate CSV Files from XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See scripts folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See scripts folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the base model\n",
    "\n",
    "base_model = ResNet50(include_top=False,\n",
    "                      weights=\"imagenet\",\n",
    "                      classifier_activation=\"softmax\",\n",
    "                      input_shape=(IMG_WIDTH, IMG_HEIGHT, 3))\n",
    "\n",
    "# Freeze layers\n",
    "\n",
    "for layer in base_model.layers[:]:\n",
    "    layer.trainable=False\n",
    "\n",
    "# Create the custom model\n",
    "\n",
    "input = Input(shape=(IMG_WIDTH, IMG_HEIGHT, 3))\n",
    "custom_model = base_model(input)\n",
    "custom_model = GlobalAveragePooling2D()(custom_model)\n",
    "custom_model = Dense(64, activation=\"relu\")(custom_model)\n",
    "custom_model = Dropout(0.5)(custom_model)\n",
    "predictions = Dense(NUM_CLASSES, activation=\"softmax\")(custom_model)\n",
    "Model(inputs=input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "\n",
    "model = custom_model\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "             optimizer=tf.train.Adam(lr=0.01),\n",
    "             metrics=[\"IoU\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
